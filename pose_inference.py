import os
import cv2
import numpy as np
import torch
import json
import sys
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ DWposeè·¯å¾„
sys.path.append('./DWPose')

# å¯¼å…¥DWposeç›¸å…³æ¨¡å—
from dwpose.wholebody import Wholebody, HWC3, resize_image
from dwpose import util

def draw_pose(pose, H, W, use_hand=False, use_body=False, use_face=False):
    """ç»˜åˆ¶éª¨éª¼å›¾"""
    bodies = pose['bodies']
    faces = pose['faces']
    hands = pose['hands']
    candidate = bodies['candidate']
    subset = bodies['subset']
    canvas = np.zeros(shape=(H, W, 3), dtype=np.uint8)

    if use_body:
        canvas = util.draw_bodypose(canvas, candidate, subset)
    if use_hand:
        canvas = util.draw_handpose(canvas, hands)
    if use_face:
        canvas = util.draw_facepose(canvas, faces)

    return canvas

class PoseProcessor:
    def __init__(self, detection_model_path, pose_model_path, device="cuda"):
        """åˆå§‹åŒ–å§¿æ€å¤„ç†å™¨"""
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        print(f"Using device: {self.device}")
        
        # åˆå§‹åŒ–DWposeæ¨¡å‹
        self.pose_estimation = Wholebody(detection_model_path, pose_model_path, device=self.device)
        self.resize_size = 1024
        
    # @torch.no_grad()
    # def process_single_image(self, image):
    #     """å¤„ç†å•å¼ å›¾ç‰‡"""
    #     # é¢„å¤„ç†
    #     input_image = HWC3(image[..., ::-1])
    #     resized_image = resize_image(input_image, self.resize_size)

    #     # æ¨ç†
    #     candidate, subset, det_result = self.pose_estimation(resized_image)

    #     # åå¤„ç†
    #     H, W, C = resized_image.shape
    #     nums, keys, locs = candidate.shape

    #     # å½’ä¸€åŒ–åæ ‡
    #     candidate[..., 0] /= float(W)
    #     candidate[..., 1] /= float(H)

    #     # é»˜è®¤é€‰æ‹©æœ€å¤§äººä½“ç›®æ ‡
    #     max_area = 0
    #     max_index = 0

    #     for i in range(nums):
    #         # ä»subsetè·å–èº«ä½“å…³é”®ç‚¹ç½®ä¿¡åº¦ï¼ˆå‰18ä¸ªï¼‰
    #         body_conf = subset[i, :18]  # å½¢çŠ¶ (18,)

    #         # è®¡ç®—æœ‰æ•ˆå…³é”®ç‚¹æ•°é‡
    #         valid_count = (body_conf > 0.3).sum()
    #         if valid_count < 5:  # è‡³å°‘éœ€è¦5ä¸ªæœ‰æ•ˆå…³é”®ç‚¹
    #             continue

    #         # è·å–å½“å‰äººä½“çš„æ‰€æœ‰å…³é”®ç‚¹ï¼ˆåŒ…æ‹¬x,yï¼‰
    #         body_kpts = candidate[i, :18]  # å½¢çŠ¶ (18, 2)

    #         # ä½¿ç”¨subsetç½®ä¿¡åº¦ç­›é€‰æœ‰æ•ˆå…³é”®ç‚¹
    #         valid_mask = body_conf > 0.3
    #         valid_kpts = body_kpts[valid_mask]

    #         # è®¡ç®—åŒ…å›´ç›’é¢ç§¯
    #         x_min, x_max = valid_kpts[:, 0].min(), valid_kpts[:, 0].max()
    #         y_min, y_max = valid_kpts[:, 1].min(), valid_kpts[:, 1].max()
    #         area = (x_max - x_min) * (y_max - y_min)

    #         if area > max_area:
    #             max_area = area
    #             max_index = i

    #     if max_area == 0:
    #         return None, None, (0, 0)

    #     # åªä¿ç•™æœ€å¤§äººä½“çš„å…³é”®ç‚¹
    #     candidate = candidate[max_index:max_index + 1]
    #     subset = subset[max_index:max_index + 1]

    #     # æå–èº«ä½“å…³é”®ç‚¹
    #     body = candidate[:, :18].copy()
    #     body = body.reshape(1 * 18, locs)  # ä¿®æ”¹ä¸ºåªå¤„ç†ä¸€ä¸ªäººä½“
    #     score = subset[:, :18]

    #     # å¤„ç†ç½®ä¿¡åº¦
    #     for i in range(len(score)):
    #         for j in range(len(score[i])):
    #             if score[i][j] > 0.3:
    #                 score[i][j] = int(18 * i + j)
    #             else:
    #                 score[i][j] = -1

    #     un_visible = subset < 0.3
    #     candidate[un_visible] = -1

    #     # æå–å…¶ä»–å…³é”®ç‚¹ï¼ˆåªä¿ç•™æœ€å¤§äººä½“çš„ï¼‰
    #     foot = candidate[:, 18:24]
    #     faces = candidate[:, 24:92]
    #     hands = candidate[:, 92:113]
    #     hands = np.vstack([hands, candidate[:, 113:]])

    #     bodies = dict(candidate=body, subset=score)
    #     pose = dict(bodies=bodies, hands=hands, faces=faces)

    #     return pose, det_result[max_index] if det_result is not None else None, (H, W)


    @torch.no_grad()
    def process_single_image(self, image):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        # é¢„å¤„ç†
        input_image = HWC3(image[..., ::-1])
        resized_image = resize_image(input_image, self.resize_size)

        # æ¨ç†
        candidate, subset, det_result = self.pose_estimation(resized_image)
        H, W, C = resized_image.shape
        if 0 in candidate.shape or 0 in subset.shape or 0 in det_result.shape:
            return None, None, (H, W)
        
        # print(f"############################ Detected shape ###########################")
        # print(f"candidate shape: {candidate.shape}, subset shape: {subset.shape}, det_result shape: {det_result.shape if det_result is not None else None}")

        # åå¤„ç†
        nums, keys, locs = candidate.shape

        # å½’ä¸€åŒ–åæ ‡
        candidate[..., 0] /= float(W)
        candidate[..., 1] /= float(H)

        # é»˜è®¤é€‰æ‹©æœ€å¤§äººä½“ç›®æ ‡
        max_area = 0
        max_index = -1

        for i in range(nums):

            # ç›´æ¥ä»subsetè·å–èº«ä½“å…³é”®ç‚¹ç½®ä¿¡åº¦ï¼ˆå‰18ä¸ªï¼‰
            body_conf = subset[i, :18]  # å½¢çŠ¶ (18,)

            # è®¡ç®—æœ‰æ•ˆå…³é”®ç‚¹æ•°é‡
            valid_count = (body_conf > 0.3).sum()
            if valid_count < 5:  # è‡³å°‘éœ€è¦5ä¸ªæœ‰æ•ˆå…³é”®ç‚¹
                continue

            # è·å–å½“å‰äººä½“çš„æ‰€æœ‰å…³é”®ç‚¹ï¼ˆåŒ…æ‹¬x,yï¼‰
            body_kpts = candidate[i, :18]  # å½¢çŠ¶ (18, 2)

            # ä½¿ç”¨subsetç½®ä¿¡åº¦ç­›é€‰æœ‰æ•ˆå…³é”®ç‚¹
            valid_mask = body_conf > 0.3
            valid_kpts = body_kpts[valid_mask]

            # è®¡ç®—åŒ…å›´ç›’é¢ç§¯
            x_min, x_max = valid_kpts[:, 0].min(), valid_kpts[:, 0].max()
            y_min, y_max = valid_kpts[:, 1].min(), valid_kpts[:, 1].max()
            area = (x_max - x_min) * (y_max - y_min)

            if area > max_area:
                max_area = area
                max_index = i

        if max_index == -1:
            return None, None, (H, W)

        # åªä¿ç•™æœ€å¤§äººä½“çš„å…³é”®ç‚¹
        candidate = candidate[max_index:max_index + 1]
        subset = subset[max_index:max_index + 1]

        # æå–èº«ä½“å…³é”®ç‚¹
        body = candidate[:, :18].copy()
        body = body.reshape(1 * 18, locs)  # ä¿®æ”¹ä¸ºåªå¤„ç†ä¸€ä¸ªäººä½“
        score = subset[:, :18]

        # å¤„ç†ç½®ä¿¡åº¦
        for i in range(len(score)):
            for j in range(len(score[i])):
                if score[i][j] > 0.3:
                    score[i][j] = int(18 * i + j)
                else:
                    score[i][j] = -1

        un_visible = subset < 0.3
        candidate[un_visible] = -1

        # æå–å…¶ä»–å…³é”®ç‚¹ï¼ˆåªä¿ç•™æœ€å¤§äººä½“çš„ï¼‰
        foot = candidate[:, 18:24]
        faces = candidate[:, 24:92]
        hands = candidate[:, 92:113]
        hands = np.vstack([hands, candidate[:, 113:]])

        bodies = dict(candidate=body, subset=score)
        pose = dict(bodies=bodies, hands=hands, faces=faces)

        return pose, det_result[max_index], (H, W)

    def process_frames_batch(self, frames_dir, output_dir, output_json_path, batch_size=8):
        """æ‰¹é‡å¤„ç†å¸§åºåˆ—å¹¶ä¿å­˜ä¸ºå›¾ç‰‡åºåˆ—"""
        # è·å–æ‰€æœ‰å¸§æ–‡ä»¶
        frame_files = sorted([f for f in os.listdir(frames_dir)
                              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])

        if not frame_files:
            print("No image files found!")
            return

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # è¯»å–ç¬¬ä¸€å¸§è·å–å°ºå¯¸ä¿¡æ¯
        first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))
        if first_frame is None:
            print("Cannot read first frame!")
            return

        frame_height, frame_width = first_frame.shape[:2]

        keypoints_list = []
        processed_count = 0

        # æ‰¹é‡å¤„ç†
        for i in tqdm(range(0, len(frame_files), batch_size), desc="Processing frames", leave=False):
            batch_files = frame_files[i:i + batch_size]

            for fname in batch_files:
                frame_path = os.path.join(frames_dir, fname)
                frame = cv2.imread(frame_path)

                if frame is None:
                    print(f"Warning: Cannot read frame {fname}")
                    keypoints_list.append(None)
                    continue

                try:
                    # å¤„ç†å•å¸§
                    pose, det_result, (H, W) = self.process_single_image(frame)

                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººä½“ï¼Œä¿å­˜ç©ºç™½å›¾åƒ
                    if pose is None:
                        # skeleton_img = np.zeros((H, W, 3), dtype=np.uint8)
                        skeleton_img = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)
                        keypoints_list.append(None)
                    else:
                        # ç”Ÿæˆéª¨éª¼å›¾
                        skeleton_img = draw_pose(pose, H, W, use_body=True, use_face=True)

                        # ä¿å­˜å…³é”®ç‚¹
                        if det_result is not None and len(det_result) > 0:
                            w_ratio, h_ratio = frame_width / W, frame_height / H
                            det_result[..., ::2] *= h_ratio
                            det_result[..., 1::2] *= w_ratio
                            det_result = det_result.astype(np.int32)
                            keypoints_list.append(det_result.tolist())
                        else:
                            keypoints_list.append(None)

                    # è°ƒæ•´å›åŸå§‹å°ºå¯¸å¹¶è½¬æ¢é¢œè‰²ç©ºé—´
                    skeleton_img = cv2.resize(skeleton_img[..., ::-1], (frame_width, frame_height),
                                              interpolation=cv2.INTER_LANCZOS4 if frame_height * frame_width > H * W else cv2.INTER_AREA)

                    # ä¿å­˜éª¨éª¼å›¾
                    output_path = os.path.join(output_dir, fname)
                    cv2.imwrite(output_path, skeleton_img)

                    processed_count += 1

                except Exception as e:
                    print(f"Error processing frame {fname}: {e}")
                    keypoints_list.append(None)

        # ä¿å­˜å…³é”®ç‚¹json
        with open(output_json_path, "w", encoding='utf-8') as f:
            json.dump(keypoints_list, f, ensure_ascii=False, indent=2)

def is_video_processed(video_dir, video_name):
    """
    éªŒè¯è§†é¢‘æ–‡ä»¶æ˜¯å¦å·²å®Œæ•´å¤„ç†
    
    å‚æ•°:
        video_dir (str): è§†é¢‘ç›®å½•è·¯å¾„
        video_name (str): è§†é¢‘åç§°
    
    è¿”å›:
        tuple: (æ˜¯å¦å·²å¤„ç†, framesæ•°é‡, skeletonsæ•°é‡)
    """
    frames_dir = os.path.join(video_dir, "frames")
    skeletons_dir = os.path.join(video_dir, "skeletons")
    json_path = os.path.join(video_dir, f"{video_name}_keypoints.json")
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files_exist = (
        os.path.exists(skeletons_dir) and 
        os.path.exists(json_path) and 
        os.path.exists(frames_dir)
        )
    
    if not required_files_exist:
        return False, 0, 0
    
    try:
        # ç»Ÿè®¡æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶æ•°é‡
        frame_files = [f for f in os.listdir(frames_dir) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        skeleton_files = [f for f in os.listdir(skeletons_dir) 
                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        # æ£€æŸ¥æ•°é‡æ˜¯å¦ä¸€è‡´ä¸”ä¸ä¸ºç©º
        is_complete = (
            len(frame_files) > 0 and 
            len(frame_files) == len(skeleton_files))
        
        return is_complete, len(frame_files), len(skeleton_files)
    
    except Exception as e:
        print(f"éªŒè¯è§†é¢‘ {video_name} æ—¶å‡ºé”™: {str(e)}")
        return False, 0, 0

def verify_dataset(data_dir, video_dirs):
    """
    éªŒè¯æ•´ä¸ªæ•°æ®é›†çš„å¤„ç†å®Œæ•´æ€§
    
    å‚æ•°:
        data_dir (str): æ•°æ®é›†æ ¹ç›®å½•
        video_dirs (list): è§†é¢‘ç›®å½•åˆ—è¡¨
    
    è¿”å›:
        tuple: (ç¼ºå¤±è§†é¢‘åˆ—è¡¨, å¸§æ•°ä¸åŒ¹é…è§†é¢‘åˆ—è¡¨)
    """
    missing_videos = []
    frame_mismatch_videos = []
    
    for video_name in video_dirs:
        video_dir = os.path.join(data_dir, video_name)
        is_processed, frame_count, skeleton_count = is_video_processed(video_dir, video_name)
        
        if frame_count != skeleton_count:
            frame_mismatch_videos.append((video_name, frame_count, skeleton_count))
        elif not is_processed:
            missing_videos.append(video_name)
    
    return missing_videos, frame_mismatch_videos

def main():
    """ä¸»å‡½æ•°"""
    # å¯¼å…¥é…ç½®
    import pose_config
    
    # é…ç½®è·¯å¾„
    detection_model_path = pose_config.DETECTION_MODEL_PATH
    pose_model_path = pose_config.POSE_MODEL_PATH
    data_dir = "result_data"  # æ•°æ®æ ¹ç›®å½•
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(detection_model_path):
        print(f"Detection model not found: {detection_model_path}")
        return
        
    if not os.path.exists(pose_model_path):
        print(f"Pose model not found: {pose_model_path}")
        return
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(data_dir):
        print(f"Data directory not found: {data_dir}")
        return

    # è·å–è§†é¢‘ç›®å½•åˆ—è¡¨
    video_dirs = [d for d in os.listdir(data_dir) 
                 if os.path.isdir(os.path.join(data_dir, d))]
    video_dirs = sorted(list(set(video_dirs)))

    # å–åä¸‰åˆ†ä¹‹ä¸€çš„è§†é¢‘æ–‡ä»¶
    # start_index = len(video_dirs) // 2  # è®¡ç®—ä¸‰åˆ†ä¹‹äºŒå¤„ä½œä¸ºèµ·å§‹ç‚¹
    # video_dirs = video_dirs[-4300:]  # ä»èµ·å§‹ç‚¹åˆ°æœ«å°¾

    if not video_dirs:
        print("â„¹ No valid video directories found in data folder")
        return
    
    print(f"ğŸ” Found {len(video_dirs)} videos to process")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = PoseProcessor(detection_model_path, pose_model_path)

    # ç»Ÿè®¡å˜é‡
    processed_count = 0
    skipped_count = 0
    failed_count = 0
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
    for video_name in tqdm(video_dirs, desc="Processing videos"):
        video_dir = os.path.join(data_dir, video_name)
        frames_dir = os.path.join(video_dir, "frames")
        skeletons_dir = os.path.join(video_dir, "skeletons")
        json_path = os.path.join(video_dir, f"{video_name}_keypoints.json")
        
        # ä½¿ç”¨éªŒè¯å‡½æ•°æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        is_processed, _, _ = is_video_processed(video_dir, video_name)
        if is_processed:
            tqdm.write(f"â„¹ {video_name} already processed, skipping...")
            skipped_count += 1
            continue
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(skeletons_dir, exist_ok=True)
            
            # å¤„ç†å½“å‰è§†é¢‘çš„å¸§
            processor.process_frames_batch(frames_dir, skeletons_dir, json_path, batch_size=8)
            processed_count += 1
            tqdm.write(f"âœ” Successfully processed {video_name}")
            
        except Exception as e:
            failed_count += 1
            tqdm.write(f"âš  Failed to process {video_name}: {str(e)}")
            continue
    
    # éªŒè¯å¤„ç†ç»“æœ
    print("\nğŸ” Verifying processing results...")
    missing_videos, frame_mismatch_videos = verify_dataset(data_dir, video_dirs)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š Processing Statistics:")
    print(f"Total videos found: {len(video_dirs)}")
    print(f"Successfully processed: {processed_count}")
    print(f"Skipped (already processed): {skipped_count}")
    print(f"Failed to process: {failed_count}")
    
    if missing_videos:
        print("\nâŒ Missing skeleton data for following videos:")
        for video in missing_videos:
            print(f"- {video}")
    else:
        print("\nâœ… All videos have skeleton data!")
    
    if frame_mismatch_videos:
        print("\nâš  Frame count mismatch in following videos (frames_dir vs skeletons_dir):")
        for video, frame_count, skeleton_count in frame_mismatch_videos:
            print(f"- {video}: {frame_count} frames vs {skeleton_count} skeletons")
    else:
        print("\nâœ… All videos have matching frame counts in frames and skeletons directories!")

if __name__ == "__main__":
    main() 